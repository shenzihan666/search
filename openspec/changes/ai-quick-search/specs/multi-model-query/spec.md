# Multi-Model Query Specification

多模型并行查询能力，支持同时向多个 AI 模型发送请求。

## ADDED Requirements

### Requirement: 并行查询多个模型

系统 SHALL 支持用户同时选择多个 AI 模型进行并行查询。

#### Scenario: 选择多个模型查询
- **WHEN** 用户选择了 3 个模型（如 GPT-4、Claude、Gemini）并提交问题
- **THEN** 系统同时向 3 个模型发送请求并独立返回结果

#### Scenario: 单模型查询
- **WHEN** 用户只选择了 1 个模型并提交问题
- **THEN** 系统只向该模型发送请求

### Requirement: 流式响应

系统 SHALL 以流式方式展示每个模型的响应，实时更新内容。

#### Scenario: 流式显示响应
- **WHEN** 某个模型开始返回响应内容
- **THEN** 系统实时将内容追加到对应的响应区域，无需等待完整响应

#### Scenario: 多模型同时流式
- **WHEN** 多个模型同时返回流式响应
- **THEN** 每个模型的响应独立流式更新，互不阻塞

### Requirement: 查询超时处理

系统 SHALL 对每个模型查询设置超时时间，默认 60 秒。

#### Scenario: 单个模型超时
- **WHEN** 某个模型在 60 秒内未返回任何响应
- **THEN** 系统在该模型的响应区域显示超时错误，但不影响其他模型

#### Scenario: 用户取消查询
- **WHEN** 用户在查询过程中点击取消按钮
- **THEN** 系统取消所有正在进行的请求并停止流式更新

### Requirement: 错误隔离

系统 SHALL 确保单个模型的错误不影响其他模型的响应。

#### Scenario: 单个模型 API 错误
- **WHEN** 某个模型返回 API 错误（如 401、429）
- **THEN** 系统在该模型区域显示错误信息，其他模型继续正常响应

#### Scenario: 单个模型网络故障
- **WHEN** 某个模型因网络问题无法连接
- **THEN** 系统在该模型区域显示网络错误，其他模型继续正常响应

### Requirement: 查询进度指示

系统 SHALL 显示每个模型的查询状态。

#### Scenario: 显示查询状态
- **WHEN** 查询正在进行
- **THEN** 每个模型区域显示当前状态（等待中/正在响应/已完成/错误）

#### Scenario: 响应时间统计
- **WHEN** 某个模型完成响应
- **THEN** 系统显示该模型的总响应时间
